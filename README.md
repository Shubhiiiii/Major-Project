Image to Story Generation using CNN and Transformer

This project presents a deep learning model that takes an image as input and generates a short descriptive **story** instead of just a caption. By combining the power of **InceptionV3** for image feature extraction and a **Transformer-based encoder-decoder architecture** for sequence generation, this project aims to explore the intersection of vision and language in a creative way.

---

Demo

> Input Image:  
> Output Story: *"A young boy playing soccer on a sunny afternoon while his friends cheer from the sidelines."*

---

Features

- Story generation using **image inputs**
- Preprocessing pipeline for text and image data
- CNN encoder using **InceptionV3**
- Transformer-based decoder for sequence generation
- Attention mechanism for better alignment
- Uses **Flickr8k** dataset for training

---

Technologies Used

- Python
- TensorFlow
- NumPy, Matplotlib, PIL
- InceptionV3 (pre-trained on ImageNet)
- Transformer (custom implementation)
- Flickr8k Dataset (Images + Captions)

---

